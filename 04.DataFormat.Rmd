---
title: "Module 4: Formatting Data for Analysis"
author: "Dai Shizuka"
date: "updated `r format(Sys.time(), '%m/%d/%y')` "
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---


```{r setup, include=FALSE}
library(knitr)
#knitr::opts_chunk$set(out.width="3.5in")
```

In Module 3, we covered how to import and look at subsets of data. Here, we will deal with situations where you need to troubleshoot the data import process. Here in Module 4, we will deal with common issues that arise while importing data, as well as some best practices in data formatting. Finally, we will touch on how to change the formatting of your data set within R. 

**Note:** Excercises at the end of the module assumes you downloaded sample data as directed in Module 3. 

**Note:** Some of this material is from a free online resource from datacarpentry.org: ["Data Organization in Spreadsheets for Ecologists"](https://datacarpentry.org/spreadsheet-ecology-lesson/)

***

## 4.1 Formatting spreadsheets to keep data for analysis

This first part is not necessarily about R. It is about managing your Excel sheet in a way that facilitates data analysis outside of Excel.

One of the reasons that many formatting problems arise while keeping data in spreadsheets is that the common software (e.g., Excel) is actually used for many different purposes. For example, people often use excel to generate templates for forms (e.g., purchasing forms). Best practices for those uses of Excel are completely different from what you should do when using spreadsheets for entering data. 

Similarly, you might use spreadsheets with formatting for purposes other than keeping data for analysis (e.g., using it as a way to track progress on a project). The formatting for that kind of use is different than for storing data. 


```{r, echo=FALSE, fig.align="center", fig.cap="Spreadsheets are used for many different purposes, which explains many common formatting mistakes in data. This is a *form* made in Excel. NOT a good example of a data set.", out.width="50%"}
knitr::include_graphics("images/excel_form.png")
```

***

### 4.1.1 Basic structure of a spreadsheet

1. First line (Header) are names of variables. Each variable is one column. Do not use values as column names.

2. Each subject (animal, plant, cell, etc.) should have an ID. This is useful if you have multiple spreadsheet where you have different information about the subject--if you have a common ID, you can link together datasets more easily.

3. Each row should be an observation. If you are observing a subject multiple times (e.g., repeated measures design), each observation should be a separate line, with the measurment time/place/trial/etc. as a separate column. 

4. Don't add totals on the last line of the data. Also, avoid calculating group averages, etc. to your data. 

```{r, echo=FALSE, fig.align="center", fig.cap="Example spreadsheet of data on egg size of American Coots", out.width="100%"}
knitr::include_graphics("images/eggdata_image.png")
```

<br>

***

### 4.1.2 Spreadsheet dos and don'ts!

<br>

#### 1. **Don't** keep multiple tables in one sheet
This is one common way people have used excel sheets when your data comes from multiple sources (e.g., multiple plots). It also makes you feel like you have maximum information in the sheet. But in reality, this makes it impossible to do any global analysis. And R cannot read in this type of spreadsheet.

```{r, echo=FALSE, fig.align="center", fig.cap="example from https://datacarpentry.org/spreadsheet-ecology-lesson/02-common-mistakes"}
knitr::include_graphics("images/multitable.png")
```


***Solution:*** Just keep one sheet. If you have multiple plots, treatments, etc., make that a column in your data. Example in 4.1.1***

<br>

#### 2. **Don't** include title/metadata/table caption at the top (or bottom) of your data.

*The first row of your dataset should always be your column names (header). Don't add extra information at the top of your dataset. If you need to add extra information about the data, put it in your readme file.

*Similarly, the last line of your dataset should be the last set of observations. Don't include column totals/subtotals, etc. at the end of your dataset. This will cause problems when reading the data into R. 

#### 3. **Don't** use special characters or commas. 

Excel is capable of handling special characters that other software cannot. For example, if you have the 'degree' symbol (C$^\circ$) or 'em dash' (where "--" gets converted to one long dash), these will not be read correctly when you import data in R. Do NOT use these special characters in your data. 

Also, commas cause problems when you are saving data in .csv files because the commas are designated for separating columns. If you like to write notes in your data, just make sure you don't use commas! (e.g., if need be, you could use semi-colons)


***Solution:*** Always think about whether your inputs will be read correctly by R or other stats program. Default to non-proprietary formats. 


<br>

#### 4. **Don't** use formatting (i.e., highlighting) to convey information or make spreadsheets look pretty by merging cells.

This is a common mistake that comes from using Excel as forms. 

If you are using highlighting to indicate some information, it you can almost always just add another column to include that information as another variable (see example figure). Merged cells will make R unable to import the file.

```{r, echo=FALSE, fig.align="center", fig.cap="example from https://datacarpentry.org/spreadsheet-ecology-lesson/02-common-mistakes", out.width="100%"}
knitr::include_graphics("images/highlighting.png")
```

<br>

#### 5. **Do** use good 'null values'

* **Always put in 0 if the observed vaule is 0** (i.e., don't skip the cell just because it's 0). If you don't it becomes indistinguishable from unknown or unobserved data.

* **Don't use other numbers (e.g., 999 or -999).** This used to be common practice for some stats software. But this can cause problems because it may be inadvertently used in calculations.

* **Don't use other symbols (-, ., ?).** Again, this used to be common practice for some people, but this can cause problems because R won't know how to interpret it.

* ***Good options include:*** 
    + **Blank cells.** But only if you are careful to always put 0 when the correct value is 0.
    + **Consistent, conventional abbreviation (e.g., NA, NULL).** But note that "NA" may be used as abbreviations for other things, like "North America". But if used in a column that is otherwise numeric, R can automatically interpret this as null value.

If you are using consistent null value designations, you can specify these values as null using the `na.string=` argument within the `read.csv()` function. For example,

```{r, eval=F}
dat=read.csv("data/SampleData.csv", na.string=c("NA", "#N/A"))
```
The above code will tell R that cells with either "NA" or "#N/A" should be interpreted as missing data.

<br>

#### 6. **Do** use good column names (variable names)

* Avoid using special characters or spaces in your column names. These will automatically converted to "." when you import to R. Removing spaces or using "_" or "." instead will make your life easier.

* Use relatively short but informative column names. But keep a readme.txt file associated with your data where you store detailed information on how each variable was measured.



<br>

#### 7. **Avoid** keeping summary data along with raw data (i.e., don't make a "group means" column in your dataset). 

This is more of a suggestion than a rule. When you use formulas within Excel to calculate summary values, those formulas do not carry over when you convert the spreadsheet to .csv. This means that if you need to do any recalculations, or if you realize there are any errors in values, those summary values will become outdated. It is much easier (and better) to calculate summary values within R anyway.

***

><span style="color:purple">***Key rule in reproducible research: Try not to mess with raw data! ***</span>
>
>Once you have collected data, it is best to try to keep that raw data ***raw***. If you find coding errors or you need to subset data for your analyses, it is best to do that with R once the data has been imported. This is because data-cleaning in R is reproducible. But once you start messing with raw data, it is way too easy to lose track of what you "fixed" and what you did not. Also, there are times when you later realize that you "fixed" the data incorrectly. If you have done all of that in excel, it is difficult to go back. But if you have done everything in script, everything is reversible. 

***

## 4.2 Troubleshooting Data Import

Even when you have taken care to follow the above dos and don'ts, you will often have some kind of problem reading in files. One of the big roadblocks to using R is dealing with these bugs. 

#### Some common problems:  

* **File won't import**
    + Are you sure you saved the file as a .csv file? 
    + Is the path and file name correct?
    + Is the path and file name inside quotes?
    
* **I get a weird column that has a bunch of `NA`**
    + You probably have a column in your spreadsheet that has a value in one of the cells that you forgot about.
    
* **I have a weird column at the bottom of my data that is just a bunch of `NA`**
    + You probably have a cell at the bottom of your spreadsheet with "hidden spaces".
    + Fix: In excel, do a "Find and Replace" to replace blank space with some character (e.g., a *) and then go and find and erase those characters.

* **Column is supposed to be numeric but it is showing up as factors.**
    + You probably have a cell value in the column that is non-numeric, e.g., "#N/A" or 'hidden space'
    + Fix: You can specify what kind of characters should be interpreted as `NA` using the `na.string=` argument (see above).


***



### Group Exercise: Troubleshoot data import

Step 1: Import the `SampleData_w_errors.csv` file and look at its data structure:

```{r, eval=T}
errdat=read.csv("data/SampleData_w_errors.csv") #assuming your working directory is set to the sample data folder
errdat
```

Step 2: Fix the spreadsheet so that you get the following:

* The column called "sex" only has "female" and "male".
* The column called "size" is numeric
* The column called "weight" is numeric
* The column called "X" is removed.

See how to fix these errors in R [here](04.e.Fix_Data.html)

***

### Group Exercise 2: Improve my egg measurement data

* Click on [this link](data/EggMeasurements_example.csv) to download some real data I collected on egg sizes of American Coots (*Fulica americana*) *before* I knew anything about R or programming. 

* Save the data in the "data" subfolder within your course folder.

* Try importing the data to R and also look at the spreadsheet in Excel. 

* **Come up with as many recommendations as possible on how to improve this excel sheet.**

See the answers [here](04.e.Fix_Data.html)
