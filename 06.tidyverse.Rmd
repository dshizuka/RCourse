---
title: "Data Wrangling to plots with tidyverse packages"
author: "Dai Shizuka"
date: "updated `r format(Sys.time(), '%m/%d/%y')` "
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---

## Intro to the ['tidyverse'](https://www.tidyverse.org/)

```{r, out.width="10%", echo=F}
knitr::include_graphics("images/icons/tidyr.png")
knitr::include_graphics("images/icons/dplyr.png")
knitr::include_graphics("images/icons/stringr.png")
knitr::include_graphics("images/icons/ggplot2.png")
```

Now that we have dipped our feet into plots and stats in R, I think you are getting a better sense of the fact that 'wrangling' or 'manipulating' data is one of the biggest steps to becoming proficient in R and all that it has to offer. 

For example, for any given analysis, you may have to subset data, filter out certain data that don't meet some criteria, focus in on a select set of variables of interest, calculate means, and variance for different groups, etc. etc. 

These tasks are where the packages [dplyr](https://dplyr.tidyverse.org/), [tidyr](https://tidyr.tidyverse.org/) and other packages in the [tidyverse](https://www.tidyverse.org/)--a series of packages designed for all kinds of data tasks. This also includes the popular [ggplot2](https://ggplot2.tidyverse.org/) package for graphics. 

The tidyverse packages are constructed by [Hadley Wickam](http://hadley.nz/). There are several books that cover how to use these packages, including *R for Data Science* [which is available for free as an online book](https://r4ds.had.co.nz/)

```{r, out.width="20%", echo=F}
knitr::include_graphics("images/icons/R_for_Data_Science_cover.png")
```

In this module, we'll be learning some functions from the packages **dplyr** and **tidyr**. 

We will do this by playing with data from the World Bank.

***

## Installing and loading packages we need for this module

One can install each package separately, but you can also just install all "tidyverse" packages simply by running this command:

```{r, eval=FALSE}
install.packages("tidyverse")
install.packages("wbstats")
```

Note that this simply downloads the packages onto your computer. When you are ready to use them, you will have to load the package onto the environment by running the function

You now have the package downloaded on your computer, but to actually use it, you have to load the package. We can load the entire `tidyverse` package (or, if you prefer, you can just load the `tidyr` package).

```{r}
library(wbstats)
library(tidyverse)
```

**Two important thing to notice here.** First, the message tells you what packages were actually loaded as part of the tidyverse "metapackage". You see that this includes 8 packages: ggplot2,tibble, tidyr, readr, purrr, dplyr, stringr, and forcats. Second, the message tells you that there are two functions in the `dplyr` package that conflict with existing functions: `filter()` and `lag()`. This is sometimes very important to know! This means that the `filter()` function works differently before and after loading this package.

***

><span style="color:purple">***Some things to know about getting started with 'tidyverse'***</span>
>
>**Pipe Operator (`%>%`):**
>tidyverse makes use of the pipe operator `%>%`, which allows you to carry over the output of one function to the next function. This can make series of data manipulation sequences much more efficient. 
>
>**Tibbles:**
>"tibble" is a special class of dataframe that is used in tidyverse. It is largely the same as a dataframe but it has some features (or rather, lack of features) that make for 'defensive coding'. That is, it forces you to avoid dangerous operations, such as changing variable names or types (you have to explicitly do this) or allow "partial matching".
>
>To learn more about tibbles, start [here](https://tibble.tidyverse.org/)


***

## 2. Working with *tidyr* and *dplyr*

### 2.1. *tidyr*

I use *tidyr* mostly for reshaping data to move between "long-format" and "wide-format" data. 

Here is link to the *tidyr* cheat sheet: https://github.com/rstudio/cheatsheets/blob/master/tidyr.pdf

#### Main *tidyr* functions

* `pivot_longer()`: "lengthen" data by collapsing several columns into two.
* `pivot_wider()`: "widen" data by expanding two columns into multiple columns
* `drop_na()`: remove rows that contain NA
* `separate()`: separate values in a column into multiple columns
* `unite()`: paste together values in two columns

### 2.2. *dplyr*

*dplyr* is a package that helps you wrangle your data into shape to aid you in the process of visualization and analysis. 

Here is a link to the `dplyr` cheat sheet: https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf

#### Main *dplyr* functions

* `pull()`: select one column and save as a vector.
* `select()`: select columns by criteria
* `filter()`: filter rows by criteria
* `mutate()`: add new variable using functions
* `group_by()`: group the data together based on a given variable (or variables). Often used when calculating summary stats.
* `summarise()`: calculate summary statistic for a given variable
* `arrange()`: change order of rows
* `left_join()`, `right_join()`, `inner_join()`, `full_join()`: set of functions to help merge data tables.
* `nest_join()`: create nested datasets (advanced... I don't know how to use this yet)

<br>


***

## 3. Demonstrating the basic functions

<br>

### 3.1 Using pipes (`%>%`) to chain together sequence of actions!

First, I'm going to introduce the "pipe"--perhaps the most useful part of the tidyverse grammar (which actually comes from another amazing package called `magrittr`, if you care...).

Basically, piping is when the `%>%` operator is used to forward a value, or the result of an expression, into the next function call/expression.

Take for example the `billboard` dataset, which is part of the *tidyr* package. It contains data on rankings of songs on the Billboard Top 100 in the year 2000.

```{r}
billboard
```

You can use the `filter()` function (see more below) to show just the data for songs by The Backstreet Boys.
```{r}
filter(billboard, artist=="Backstreet Boys, The")
```

But you can run the same code by using `%>%`, like this:
```{r}
billboard %>% filter(artist=="Backstreet Boys, The")
```

What this does is tell R: "Take `billboard`. Then, filter the data to show just the songs by The Backstreet Boys. And in this case, the `filter(., )` says that the forwarded value should be used in place of ".".

... but you actually don't even need to include the "." here--tidyverse automatically applies the forwarded value as the first entry in the function, so you can just do: 

```{r}
billboard %>% filter(artist=="Backstreet Boys, The")
```

Right now, this seems a bit puzzling and not that useful... but, you will quickly see how the `%>%` operator can help you build nice pipelines (pun intended) for data wrangling!

**From here on out, I will build the codes using pipes as a default.**

<br>

### 3.2. Filter by row values

As I've shown already, you can use the `filter()` function in *dplyr* to select rows based on some criteria. 

I can actually use multiple criteria to filter data. Let's say I now want to see the data for songs by either The Backstreet Boys or N'Sync: 
```{r}
billboard %>% filter(artist=="Backstreet Boys, The" | artist=="N'Sync")
```

Recall that there is a conflict over the function name `filter()`--there is another `filter()` function in base R that is separate from the tidyverse version. To make sure you are using the version from the *dplyr* package, I often use `dplyr::filter()` when I run this function.

```{r}
billboard %>% dplyr::filter(artist=="Backstreet Boys, The" | artist=="N'Sync")
```

### 3.3. Select columns

Sometimes, you don't need all of the data. Let's say we just want to see what position each song started at--so we just want the artist, track, date entered and the week 1 rank. You can do this with `select()`

```{r}
billboard %>% select(artist, track, date.entered, wk1)
```
The nice thing about the select function is that you don't need to put the column names in quotes or anything--just type in the columns you want. 

or, type in the columns you DON'T want:
```{r}
billboard %>% select(-track, -date.entered)
```

Combining the `filter()` and `select()` functions allow you to manage the data in flexible ways. And piping makes it easy to do this:

```{r}
billboard %>% dplyr::filter(artist=="Backstreet Boys, The") %>% select(artist, track, date.entered, wk1)
```

<br>

### 3.4. Converting wide-format data to long-format data with `pivot_longer()`

"Wide-format" data is one in which each row is a subject/entity that is measured repeatedly, and each measurement appears on different columns. The `billboard` data is a prime example of wide-format data because it lists the rankings of a song for each week in separate columns.

Let's now convert this into a long-format, in which we have a column for "week" and then the rank of that song for that week in a column called "rank":

```{r}
billboard %>% pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank")
```
What happened here? 

The minimal arguments that are required in here are: 

* `data`: (self explanatory)
* `cols`: The columns that we want to collapse into a single column. Here, we want all the columns that start with "wk", which contain the ranking of that song in that week. tidyverse has a friendly function called `starts_with()` that we use here. An alternative way to do this would be to *exclude* all the other columns, which we could do with `-c(artist, track, date.entered)`
* `names_to`: The name of a new column that will contain names of the columns that you collapsed. Here, naming this "week" makes sense.
* `values_to`: The name of a new column that will have the values for each ID x names_from combination. In this case, this is "rank"


### 3.5.  Converting long-format data to wide-format data with `pivot_wider()`

Let's save the long-format version of the billboard data:
```{r}
bb_long=billboard %>% pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank")
```

We can then revert back to the wide-format version this way:

```{r}
bb_long %>% pivot_wider(names_from = "week", values_from = "rank")
```
So, what happened here? 
The minimal arguments that are required in here are: 

* `data`: is `bb_long`, forwarded by the %>%
* `names_from`: The column that you want to expand into different columns. In this case, it is "age" because you want to see the heights of each tree at different ages as different columns.
* `values_from`: The column that will have the values for each ID x names_from combination. In this case, this is "height"

***

### 3.6. Group and Summarize data

*dplyr* makes the craft of summarizing data much easier... if you get comfortable with the grammar. Here, I will show you how to use `group_by()` and `summarise()` functions to get summary data by artist, like their best ranking and how many weeks they spent on the Top 100 chart.

Let's go back to the code that created the long-format version of the billboard data, but let's drop the rows that contain NAs using `drop_na()`

```{r}
billboard %>% 
  pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank") %>%
  drop_na() 
```

Now, we can calculate the "best rank" of each artist by grouping the data by "artist", and finding the minimum ranking that the artist had:
```{r}
billboard %>% 
  pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank") %>%
  drop_na() %>%
  group_by(artist) %>%
  summarise(artist.best=min(rank, na.rm=T))
```
Let's try another one: we can calculate the number of weeks that an artist spent on Top 100 by simply counting the number of rows that the artist shows up in (after having dropped all of the rows containing NAs, that should be what is left).

```{r}
billboard %>% 
  pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank") %>%
  drop_na() %>%
  group_by(artist) %>%
  summarise(artist.weeks=n())
```
We can also do both summary functions in one go. Let's do that and save the table as artist_dat:

```{r}
artist_dat=billboard %>% 
  pivot_longer(cols=starts_with("wk"), names_to="week", values_to="rank") %>%
  drop_na() %>%
  group_by(artist) %>%
  summarise(artist.weeks=n(), artist.best=min(rank))

artist_dat
```
### 3.7. Add new variables using `mutate()`

You can make new variables (columns). You'll often do this if want to calculate some new variable based on existing variables.
```{r}
artist_dat %>%
  mutate(top5= artist.best <=5) %>% #TRUE if artist's song was ever in Top 5
  mutate(weeks.prop = artist.weeks/max(artist.weeks)) #weeks on list as proportion of maximum value
```

### 3.8. Join two different data

The four main join functions all seek to merge data using matching columns (either matching column names, or manually designated using the `by=` argument). But they differ in which rows they will keep:

* `left_join(x, y)`: match up the values in designated columns of x and y, and keep all rows in x. NAs show up when a value is present in x but not y.

* `right_join(x, y)`: match up the values in designated columns of x and y, and keep all rows in y. NAs show up when a value is present in y but not x.

* `inner_join(x, y)`: match up the values in designated columns of x and y, and keep only rows in which x and y values matched. No NAs show up.

* `full_join(x, y): match up the values in designated columns of x and y, and keep all rows in x and y, even if they don't match. NAs whenever value in one table doesn't have a match in the other.

Let's demonstrate this by comparing the `billboard` data with the `artist_dat` table that we created above. The `billboard` data has more rows than `artist_dat` because some artists show up in multiple rows (if they have multiple songs in the charts). We will remove the columns with "wk" so we can see the results more easily.

```{r, message=F}
left_join(billboard, artist_dat) %>%
  select(-starts_with("wk"), -date.entered)
```

You can see that whenever the artist has multiple songs on the list, the "artist.weeks" and "artist.best" variables are repeated (because these are the stats for the artist).


## 4. Population growth trends across the world

The World Bank actually makes it very easy to download a huge amount of data very easily. You could just go to the [World Bankd Open Data site](https://data.worldbank.org/) and search for data and download them in a few clicks. There are even packages such as `WDI` and `wbstats` that allow you to query and pull data from this site from within R. 

However, for the purposes of this exercise, we will deal with several datasets that are included in the packages we have loaded above.

<br>

### 4.1. `world_bank_pop`: Population data from World Bank (2000-2017)
First is the `world_bank_pop` dataset that is included in the `tidyr` package (which is part of the the tidyverse suite). Start by pulling up the help file for the dataset

```{r, eval=F}
?world_bank_pop
```

Let's take a peak at the data, which is in "tibble" format:

```{r}
world_bank_pop
```

Notice that each country is repeated across 4 rows. This is because there are actually 4 different "indicators" for each country, and so each country x indicator combination takes up a row. The rest of the columns are years, from 2000 to 2017. 

Also notice that the numbers in the column names have a backquote, or "`" around them. In R, this allows numbers to be interpreted as text (and column names have to be text). 

So, if you wanted to pull up the "2001" column, this will NOT work...
```{r, eval=F}
world_bank_pop$2001
```

...but this will work
```{r, eval=F}
world_bank_pop$`2001`
```

<br>


***
### 4.2. Problem 1: "Countries" that are not countries: Merging datasets with `join` functions

We are going to start by diving into the `world_bank_pop` dataset. 

Let's take a peek at the dataset again and see what we have...
```{r}
world_bank_pop
```

I want to start by looking at how many unique countries we actually have here.

```{r}
length(unique(world_bank_pop$country)) #this gives us the number of unique values in the "country" column
```

You can see that there are way more "countries" here than there are in the world. As of 2022, there are 193 countries in the United Nations, though if we add soverign states that are not recognized by UN (e.g., Taiwan, Kosovo, etc.), the list is about 206... and there are more if we include disputed territories.

The reason the World Bank data has even more than that is because some of the "countries" include "aggregates" like "Arab World" or "High-income Countries". 

Unfortunately, the `world_bank_pop` dataset does not include any variables that allow us to differentiate the countries from the aggregates! However, we can solve this problem by pulling the metadata for countries from the World Bank. We can do this by using the `wb_countries()` function from the *wbstats* package. 

Let's pull the country metadata and save it as an object called "metadata":

```{r}
metadata=wb_countries()
```

```{r}
metadata
```

```{r}
head(metadata$region)
```
So this column shows us the "Aggregates". 

So, we can use this to filter the metadata to exclude the Aggregate codes. 
```{r}
metadata %>% dplyr::filter(region != "Aggregates")
```

Let's also pare down the data to a few variables we might be interested in, including region and income level:
```{r}
metadata %>% 
  dplyr::filter(region != "Aggregates") %>%
  select(iso3c, iso2c, country, region, income_level)
```

Ok, this looks useful. Let's save it as a data table called `countries`
```{r}
countries=metadata %>% 
  dplyr::filter(region != "Aggregates") %>%
  select(iso3c, iso2c, country.name=country, region, income_level) %>%
  mutate(income_level=factor(income_level, levels=c("Low income", "Lower middle income", "Upper middle income", "High income")))
```

Now, we are going to use the `inner_join()` function to make a version of the world bank population data that is only for actual countries (not aggregates):
```{r}
popdat_countries=inner_join(world_bank_pop, countries, by=c("country" = "iso3c"))
popdat_countries
```


### 4.3. Narrow down the data to large countries

As mentioned above (Section 1.1), each row is a country x indicator combination, with 4 different indicators. The indicators are:

* SP.POP.GROW = population growth

* SP.POP.TOTL = total population

* SP.URB.GROW = urban population growth

* SP.URB.TOTL = total urban population


So, we will create a data table called `pop_totals` that is just the "total population" data.
```{r}
pop_totals=popdat_countries %>% 
  dplyr::filter(indicator=="SP.POP.TOTL") 

pop_totals
```

From this population size data, let's figure out what is the 90th percentile in population size in 2017. We are going to get this number by doing `pull()` to get the 2017 population sizes as a vector, and use `quantile()` to get the 90th percentile. Save that value as `upper_pop`.

```{r}
upper_pop=pop_totals %>%
  pull(`2017`) %>% 
  quantile(., probs=0.90, na.rm=T) # this function allows us to find the value at #th percentile
upper_pop
```

Now, we can use this 90th percentile value to filter the population size data to just the top 10% largest countries. We will create a one-column tibble called `large_countries()` to save this list of country bodes.
```{r}
large_countries=pop_totals %>% 
  dplyr::filter(`2017` > upper_pop) %>% 
  select(country)
large_countries
```
### 4.4. Now get the population **growth** data for the largest countries

We will now go back to the population data from countries (excluding aggregates), and then filter the data to just the population growth values, then use `right_join()` to keep only the largest 10% of countries
```{r}
popgrowth_large=popdat_countries %>% 
  dplyr::filter(indicator=="SP.POP.GROW") %>%
  right_join(., large_countries, keep=FALSE) 

popgrowth_large
```

We can convert this data into long-format. First, remove some of the variables we don't need right now, and then convert to long-format.
```{r}
popgrowth_large %>% 
  select(-indicator, -country.name, -iso2c, -region, -income_level) %>%
  pivot_longer(!country, names_to="year", values_to="growth_rate")
```
Ok, so now we can use this population growth data from large countries and plot the change over time for each country:
```{r}
popgrowth_plot=popgrowth_large %>% 
  select(-indicator, -country.name, -iso2c, -region, -income_level) %>% 
  pivot_longer(!country, names_to="year", values_to="growth_rate")

ggplot(popgrowth_plot, aes(x=as.numeric(year), y=growth_rate, color=country)) +
  geom_line() +
  theme_bw()
```

### 4.4. Exploring the relationships between income level, region, and population growth

Now, let's create a tibble that contains the population growth data, by also the income level designation for each country. We will then get the average annual population growth rate across each of the four income levels.
```{r}
popgrowth_income=popdat_countries %>% 
  dplyr::filter(indicator=="SP.POP.GROW") %>%
  dplyr::filter(is.na(income_level)==F) %>% #skip if income level is missing
  select(-indicator, -country.name, -iso2c, -region) %>% #pare down the data a bit & pivot longer
  pivot_longer(cols=-c(country, income_level), names_to="year", values_to="growth_rate") %>%
  group_by(income_level, year) %>%
  summarise(mean_se(growth_rate)) #calculates mean + standard error of the mean.
popgrowth_income
```

Let's plot this. We can draw the line, and then draw a ribbon around the line to indicate confidence interval
```{r}
ggplot(popgrowth_income, aes(x=as.numeric(year), y=y, group=income_level)) +
  geom_line(aes(color=income_level)) +
  geom_ribbon(aes(ymin=ymin, ymax=ymax), alpha=0.3, fill="gray") +
  theme_bw()
```
We can also create a plot showing how income levels have different effects on population growth rates depending on the region of the world.
```{r}
popdat_anova=popdat_countries %>% 
  dplyr::filter(indicator=="SP.POP.GROW") %>%
  select(country, `2017`, region, income_level) %>%
  dplyr::filter(income_level!="Not classified")

ggplot(popdat_anova, aes(x=income_level, y=`2017`)) +
  geom_boxplot(aes(color=income_level)) +
  facet_wrap(~region, nrow=3)
```
Lower income countries have higher population growth rate than those with high income in some regions (sub-Saharan Africa), while in others growth rate is bigger for high earners.

### 4.6. Stats
```{r}
lm.fit=lm(`2017`~region*income_level, data=popdat_anova)
summary(lm.fit)
anova(lm.fit)
```




