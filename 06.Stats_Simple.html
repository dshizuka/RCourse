<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Dai Shizuka" />


<title>Module 6: Some Simple Stats</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/sandstone.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Intro to R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
<li>
  <a href="modules.html">Modules</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Module 6: Some Simple Stats</h1>
<h4 class="author">Dai Shizuka</h4>
<h4 class="date">updated 09/13/22</h4>

</div>


<p>Many, if not most users of R take advantage of the powerful set of
statistical tools available in the programming language. Particularly
powerful are the myriad of user-generated packages (over 18,000 as of
September 2022). It is pretty much true that, if there is a package for
any conceivable type of statistical analysis!</p>
<p>There is no way that I can write modules to cover all of the types of
statistical analyses out there. Here, my goal will be to outline the
basics of how to conduct one of the most flexible and widely-used
statistical analyses across biology: Linear Models. I will cover the
basics of how to implement these in base R. Hopefully this will give you
a baseline knowledge of how analyses work, and the basic syntax that is
pretty common across most stats packages. I will also cover the basics
of how to implement visualizations of statistical tests (where
appropriate).</p>
<div id="types-of-statistical-tests-depend-on-types-of-data"
class="section level2">
<h2>1. Types of statistical tests depend on types of data</h2>
<p>It is worth first considering what kind of data you have, and which
one(s) is/are predictor variable(s) and which one is the response
variable.</p>
<div id="what-kind-of-data-do-you-have" class="section level3">
<h3>1.1. What kind of data do you have?</h3>
<ul>
<li><p><strong>Numbers</strong></p>
<ul>
<li><p><em>Continuous data</em>: Numbers that can take on any
value.</p></li>
<li><p><em>Binary data</em>: Data that are 0/1 (e.g., death/survival,
below/above a threshold, etc.)</p></li>
<li><p><em>Count data</em>: Integers (e.g., number of plants, number of
hits, etc.)</p></li>
<li><p><em>Proportion data</em>: These can take a value between 0 and
1.</p></li>
</ul></li>
<li><p><strong>Factors (i.e., Categorical Data)</strong></p></li>
</ul>
</div>
<div id="predictor-vs.-response-variable" class="section level3">
<h3>1.2. Predictor vs. response variable</h3>
<p>Statistical analyses seek to determine the effect of the
<strong>predictor variable(s)</strong> on a <strong>response
variable</strong> (or, for multivariate analyses, multiple response
variables).</p>
<div id="here-are-some-of-the-most-common-scenarios"
class="section level4">
<h4>Here are some of the most common scenarios:</h4>
<ul>
<li><p><strong><em>If you have a continuous predictor AND continuous
response variable…</em></strong> use linear regression or Generalized
Linear Model (GLM) with Gaussian distribution</p></li>
<li><p><strong><em>If you have a continuous predictor AND binary
response variable…</em></strong> use GLM w/ “binomial” family (aka
logistic regression)</p></li>
<li><p><strong><em>If you have a continuous predictor AND counts as
response variable…</em></strong> use GLM w/ “Poisson” family (aka
Poisson regression)</p></li>
<li><p><strong><em>If you have a continuous predictor AND proportions as
response variable…</em></strong> use GLM w/ “binomial” or
Quasi-binomial” family</p></li>
<li><p><strong><em>If you have a categorical predictor AND continuous
response variable…</em></strong> use ANOVA (or t-test, if you are just
comparing means), which can be run as linear model or GLM.</p></li>
<li><p><strong><em>If you have multiple predictors, with some continuous
and some categorical variables…</em></strong> You can still use linear
regression / GLM!</p></li>
</ul>
<blockquote>
<p><span style="color:purple"><strong>Everything is a
GLM!</strong></span></p>
<p>You will notice from above that everything I’ve listed falls under
“GLM” or Generalized Linear Model. GLMs are super useful and flexible,
and goes beyond a lot of the “parametric statistics” that you may first
learn in basic stats class. It is one of the most common forms of
statistical analyses in biology (I think… at least in my fields of
ecology/evolution/behavior), so it is a good place to start!</p>
</blockquote>
<hr />
</div>
</div>
</div>
<div id="conducting-and-visualizing-statistical-results"
class="section level2">
<h2>2. Conducting and visualizing statistical results</h2>
<p>Now, we will use some example data available from R packages to
demonstrate how to implement different forms of GLMs. We will need the
ggplot2 package for some of the datasets and for visualization, so let’s
go ahead and load that package:</p>
<pre class="r"><code>library(ggplot2)</code></pre>
<pre><code>## Warning in register(): Can&#39;t find generic `scale_type` in package ggplot2 to
## register S3 method.</code></pre>
<div id="linear-regression-or-glm-with-gaussian-link"
class="section level3">
<h3>2.1 Linear Regression, or “GLM with Gaussian link”</h3>
<p>Let’s start by exploring the effect of one continuous variable on
another continuous variable using a linear regression.</p>
<p>One easy way to think about linear regression is that it is
appropriate whenever your predictor and response variables can be
plotted as a scatterplot.</p>
<p>To demonstrate linear regression, we will use a dataset called
<code>mtcars</code>. This is a dataset on the performance of car models
from 1974 <em>Motor Trend US</em> magazine.</p>
<pre class="r"><code>?mtcars
head(mtcars)</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<p>First, let’s plot something… like the relationship between the weight
of the car and its fuel efficiency</p>
<pre class="r"><code>plot(mpg~wt, data=mtcars, pch=19)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>You can see there is going to be some strong relationship here. Let’s
investigate this as a linear regression using the function
<code>lm()</code>:</p>
<pre class="r"><code>lm.mod=lm(mpg~wt, data=mtcars)
summary(lm.mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5432 -2.3647 -0.1252  1.4096  6.8727 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
## wt           -5.3445     0.5591  -9.559 1.29e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.046 on 30 degrees of freedom
## Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 
## F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
<p>You can see this is a very strong relationship, with <span
class="math inline">\(R^2 = 0.74\)</span> and very low P-value.</p>
<p>We can plot this relationship onto the scatterplot:</p>
<pre class="r"><code>plot(mpg~wt, data=mtcars, pch=19)
lm.mod=lm(mpg~wt, data=mtcars)
xv=seq(min(mtcars$wt), max(mtcars$wt), length=2)
yv=predict(lm.mod, data.frame(wt=xv))
lines(xv, yv)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
</div>
<div id="anova-comparing-a-continuous-variable-across-groups"
class="section level2">
<h2>2. ANOVA: Comparing a continuous variable across groups</h2>
<div id="a-simple-example-with-chickwts" class="section level3">
<h3>2.1 A simple example with <code>chickwts</code></h3>
<p>Analysis of Variance (ANOVA) is a way to compare whether groups
(e.g., different sites, different treatments, etc.) differ in some
measured continuous variable. What ANOVA does is partition variation
into within-group and across-group variation. We conclude that groups
are different if the variation across groups is much larger than the
variation within groups.</p>
<p>Let’s first start by plotting a bar plot and standard errors of the
means (SEMs) for the <code>chickwts</code> dataset, which is pre-loaded
in R. This dataset comes from an experiment where newly hatched chicks
were randomly allocated into 6 groups, and each group was fed with a
different feed supplement. The chicks were all weighed at 6 weeks
old.</p>
<p>Let’s check out the dataset first:</p>
<pre class="r"><code>?chickwts #This will give you a help file that includes information about the dataset. 
head(chickwts)</code></pre>
<pre><code>##   weight      feed
## 1    179 horsebean
## 2    160 horsebean
## 3    136 horsebean
## 4    227 horsebean
## 5    217 horsebean
## 6    168 horsebean</code></pre>
<p>Now let’s try plotting the data.</p>
<pre class="r"><code>plot(weight~feed,data=chickwts)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We get the sense that there are some differences in chick weights
based on feed supplement. Let’s test this hypothesis with ANOVA using
the <code>aov()</code> function.</p>
<pre class="r"><code>aov.mod=aov(weight~feed, data=chickwts) 
summary(aov.mod)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## feed         5 231129   46226   15.37 5.94e-10 ***
## Residuals   65 195556    3009                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The output answers are major question: Yes, there is a significant
difference between treatments.</p>
</div>
<div id="testing-assumptions-of-anova" class="section level3">
<h3>2.2 Testing Assumptions of ANOVA</h3>
<p>The second thing we’ll likely want to do is to test our assumptions.
You can do this graphically:</p>
<pre class="r"><code>plot(aov.mod)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-9-1.png" width="384" /><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-9-2.png" width="384" /><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-9-3.png" width="384" /><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-9-4.png" width="384" /></p>
<p>The first plot looks at residual vs. fitted values—if there are weird
patterns here, e.g., the points “fan out” towards the right side of the
plot, then you might have heteroscedasticity (variance differs across
treatments with different means). The second plot looks for non-
normality of errors. Ideally, you want this “qqplot” to look fairly
straight. The third plot is the “standardized” (or “studentized”)
residuals plotted against the fitted values—this should also look fairly
flat. The fourth plot looks for patterns related to leverage, or the
degree of influence a data point has on the patterns.</p>
<p>Another way to check for heteroscedasticity in the data is to use
statistical tests, such as Bartlett test, Fligner-Killeen test, or
Levene’s test. E.g.,</p>
<pre class="r"><code>fligner.test(weight~feed,data=chickwts)</code></pre>
<pre><code>## 
##  Fligner-Killeen test of homogeneity of variances
## 
## data:  weight by feed
## Fligner-Killeen:med chi-squared = 3.8109, df = 5, p-value = 0.577</code></pre>
<p>This test suggests that the groups have no significant differences in
variance, so that’s good.</p>
</div>
<div id="posthoc-tests" class="section level3">
<h3>2.3 Posthoc tests</h3>
<p>The above ANOVA analysis told us that there are differences among
groups. However, that is not quite that useful. What we really want to
know is which groups are different from each other? To ask this
question, you need to conduct pairwise comparisons. You could do a
series of two-sample t-tests, but this is not so robust when you do too
many comparisons at once. A standard procedure for post-hoc multiple
comparisons is the Tukey’s HSD (hostly significant difference) test. You
can conduct that simply in R:</p>
<pre class="r"><code>thsd=TukeyHSD(aov.mod) 
thsd</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = weight ~ feed, data = chickwts)
## 
## $feed
##                            diff         lwr       upr     p adj
## horsebean-casein    -163.383333 -232.346876 -94.41979 0.0000000
## linseed-casein      -104.833333 -170.587491 -39.07918 0.0002100
## meatmeal-casein      -46.674242 -113.906207  20.55772 0.3324584
## soybean-casein       -77.154762 -140.517054 -13.79247 0.0083653
## sunflower-casein       5.333333  -60.420825  71.08749 0.9998902
## linseed-horsebean     58.550000  -10.413543 127.51354 0.1413329
## meatmeal-horsebean   116.709091   46.335105 187.08308 0.0001062
## soybean-horsebean     86.228571   19.541684 152.91546 0.0042167
## sunflower-horsebean  168.716667   99.753124 237.68021 0.0000000
## meatmeal-linseed      58.159091   -9.072873 125.39106 0.1276965
## soybean-linseed       27.678571  -35.683721  91.04086 0.7932853
## sunflower-linseed    110.166667   44.412509 175.92082 0.0000884
## soybean-meatmeal     -30.480519  -95.375109  34.41407 0.7391356
## sunflower-meatmeal    52.007576  -15.224388 119.23954 0.2206962
## sunflower-soybean     82.488095   19.125803 145.85039 0.0038845</code></pre>
<p>This test suggests that there are significance difference
between:</p>
<ul>
<li>linseed vs. casein</li>
<li>soybean vs. casein</li>
<li>meatmeal vs. horsebean</li>
<li>soybean vs. horsebean</li>
<li>sunflower vs. horsebean</li>
<li>sunflower vs. linseed</li>
<li>sunflower vs. soybean</li>
</ul>
<p>Look at the boxplot again and see if those results make sense:</p>
<pre class="r"><code>plot(weight~feed,data=chickwts)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<table>
<colgroup>
<col width="29%" />
<col width="39%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Test</th>
<th>Description</th>
<th>Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Two-sample T-Test</td>
<td>Parametric test of means of two groups</td>
<td><code>t.test()</code></td>
</tr>
<tr class="even">
<td>Mann-Whitney U-test</td>
<td>Non-parametric version of two-sample t</td>
<td><code>wilcox.test()</code></td>
</tr>
<tr class="odd">
<td>Kruskall-Wallis test</td>
<td>Non-parametric comparison of two or more groups</td>
<td><code>kruskal.test()</code></td>
</tr>
<tr class="even">
<td>Welch’s test</td>
<td>ANOVA with relaxed assumption about heterogeneous variances</td>
<td><code>oneway.test()</code></td>
</tr>
<tr class="odd">
<td>Paired t-test</td>
<td>Two-sample t-test for repeated measures</td>
<td><code>t.test(paired=TRUE)</code></td>
</tr>
<tr class="even">
<td>Wilcoxon signed-rank test</td>
<td>Nonparametric version of paired t</td>
<td><code>Wilcox.test(paired=TRUE)</code></td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div
id="ancova-testing-the-effects-of-a-continuous-variable-a-categorical-factor"
class="section level2">
<h2>4. ANCOVA: Testing the effects of a continuous variable &amp; a
categorical factor</h2>
<p>###4.1 Performing an ANCOVA</p>
<p>Continuing with the above example using <code>mtcars</code> … Let’s
look a little bit closer at the data. Now we will plot the relationship
between car weight and fuel efficiency, but looking at automatic
vs. manual transmission cars.</p>
<pre class="r"><code>my.pal=c(&quot;tomato&quot;, &quot;slateblue&quot;)
plot(mpg~wt, data=mtcars, pch=19, col=my.pal[as.numeric(mtcars$am)+1], cex=2)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>The <code>mtcars$am</code> variable is 0 = automatic and 1 = manual
(see help file <code>?mtcars</code>). So the above code will put the
automatic transmission in “tomato” and manual transmission in
“slateblue”.</p>
<p>Overall, it seems that manual transmission is lighter, and it also
tends to get better gas mileage. But is the relationship between weight
and fuel efficiency different between the two transmission types? This
is the question we can get at with an ANCOVA.</p>
<p>There are at least two ways to do this.</p>
<p>Option 1: Use <code>aov()</code> to fit model and see output using
<code>summary()</code></p>
<pre class="r"><code>mtcars$trans.type=factor(mtcars$am)
ancova.mod1=aov(mpg~wt*trans.type, data=mtcars)
summary(ancova.mod1)</code></pre>
<pre><code>##               Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## wt             1  847.7   847.7  126.25 6.92e-12 ***
## trans.type     1    0.0     0.0    0.00  0.98556    
## wt:trans.type  1   90.3    90.3   13.45  0.00102 ** 
## Residuals     28  188.0     6.7                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Option 1: Use <code>lm()</code> to fit model and use
<code>anova()</code> to see output</p>
<pre class="r"><code>ancova.mod2=lm(mpg~wt*trans.type, data=mtcars)
anova(ancova.mod2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: mpg
##               Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
## wt             1 847.73  847.73 126.2518 6.915e-12 ***
## trans.type     1   0.00    0.00   0.0003  0.985556    
## wt:trans.type  1  90.31   90.31  13.4502  0.001017 ** 
## Residuals     28 188.01    6.71                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You can see that they give you identical results (with one-digit
difference in rounding).</p>
<div id="plotting-the-results" class="section level3">
<h3>4.2 Plotting the results</h3>
<p>Ok, so the above results suggest that there is some <em>interaction
effect</em> between weight and transmission type on fuel efficiency.
Let’s visualize this by running two linear models independently on each
transmission type and then drawing the model fits on top of the scatter
plots.</p>
<pre class="r"><code>auto.dat=subset(mtcars, am==0)
manu.dat=subset(mtcars, am==1)
lm.auto=lm(mpg~wt, data=auto.dat)
lm.manu=lm(mpg~wt, data=manu.dat)
my.pal=c(&quot;tomato&quot;, &quot;slateblue&quot;)
plot(mpg~wt, data=mtcars, pch=19, col=my.pal[as.numeric(mtcars$am)+1], cex=2)
abline(lm.auto, col=&quot;tomato&quot;, lwd=2)
abline(lm.manu, col=&quot;slateblue&quot;, lwd=2)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>A more complicated routine, but a prettier plot:</p>
<pre class="r"><code>my.pal=c(&quot;tomato&quot;, &quot;slateblue&quot;)
plot(mpg~wt, data=mtcars, pch=19, col=my.pal[as.numeric(mtcars$am)+1], cex=2)

xv0=seq(min(auto.dat$wt), max(auto.dat$wt), length=10)
yv0=predict(lm.auto, data.frame(wt=xv0))
lines(xv0, yv0, col=&quot;tomato&quot;, lwd=2)

xv1=seq(min(manu.dat$wt), max(manu.dat$wt), length=11)
yv1=predict(lm.manu, data.frame(wt=xv1))
lines(xv1, yv1, col=&quot;slateblue&quot;, lty=2, lwd=2)</code></pre>
<p><img src="06.Stats_Simple_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="linear-mixed-models" class="section level2">
<h2>Linear Mixed Models</h2>
<p>Mixed effects models are often used to analyze ‘nested’ or
‘hierarchical’ data. For example, in a repeated measures design, the
same measurement is taken from a subject over different times and
perhaps different treatments. If your objective is to understand the
overall effects of time or treatment, then you want to account for
variations among individuals.</p>
<p>There are several packages for conducting mixed-effects models in R.
Perhaps the most commonly used package is <code>lme4()</code>. Use the
codes below to load the package, learn about one of the datasets that
come with the package (called <code>sleepstudy</code>) and a simple use
of the <code>lmer()</code> function to conduct a mixed model
analysis.</p>
<blockquote>
<p><span style="color:purple"><strong>Downloading and installing
packages</strong></span></p>
<p>To do this part, you will need to download and install a stats
package that can handle linear mixed-effects models. The one we will use
here is <code>lme4</code>.</p>
</blockquote>
<blockquote>
<p>You can install this package by running the command:
<code>install.packages('lme4')</code> In addition, we will use the
<code>lmerTest</code> package to generate a P-value from the linear
mixed-effects model. To install that package, run
<code>install.packages('lmerTest')</code></p>
</blockquote>
<pre class="r"><code>library(lme4) 
library(lmerTest)
?sleepstudy</code></pre>
<pre class="r"><code>mix.mod1=lmer(Reaction~Days+ (Days|Subject), data=sleepstudy) #mixed effects model of Days, with Days nested in Subject as random effect summary(mix.mod1) #summary of lmer output does not give you p-values
anova(mix.mod1)</code></pre>
<pre><code>## Type III Analysis of Variance Table with Satterthwaite&#39;s method
##      Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    
## Days  30024   30024     1 16.995  45.843 3.273e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
